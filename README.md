# Awesome MyPhD [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

An up-to-date library on all papers and codes relevant to my PhD


## Activation Steering on LLMs and VLMs
- **[ActAdd]** Steering Language Models Without Optimization [[pdf]](https://arxiv.org/pdf/2308.10248v4)
- **[FGAA]** Interpretable Steering of Large Language Models with Feature Guided Activation Additions [[pdf]](https://openreview.net/pdf?id=swRxS7s4rB)
- **[CAA]** Steering Llama 2 via Contrastive Activation Addition [[pdf]](https://arxiv.org/pdf/2312.06681)
- **[ICV]** Making In Context Learning More Effective and Controllable Through Latent Space Steering [[pdf]](https://arxiv.org/pdf/2311.06668) [[code]](https://github.com/shengliu66/ICV)
- **[ACT]** Controlling Language and Diffusion Models by Transporting Activations [[pdf]](https://openreview.net/pdf?id=l2zFn6TIQi) [[code]](https://github.com/apple/ml-act)
- **[CAST]** Programming Refusal with Conditional Activation Steering [[pdf]](https://openreview.net/pdf?id=Oi47wc10sm) [[code]](https://github.com/IBM/activation-steering)
- **[GrAInS]** Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs [[pdf]](https://arxiv.org/pdf/2507.18043) [[code]](https://github.com/duykhuongnguyen/GrAInS?tab=readme-ov-file)
- **[Cache Steering]** KV Cache Steering for Controlling Frozen LLMs [[pdf]](https://arxiv.org/pdf/2507.08799) [[code]](https://github.com/MaxBelitsky/cache-steering)
- **[AlphaEdit]** Null-Space Constrained Knowledge Editing for Language Models [[pdf]](https://openreview.net/pdf?id=HvSytvg3Jh) [[code]](https://github.com/jianghoucheng/AlphaEdit)
- Understanding Reasoning in Thinking Language Models via Steering Vectors [[pdf]](https://openreview.net/pdf?id=OwhVWNOBcz)
- Function Vectors in Large Language Models [[pdf]](https://openreview.net/pdf?id=AwyxtyMwaG) [[code]](https://github.com/ericwtodd/function_vectors) [[website]](https://functions.baulab.info/)
- In-Context Learning Creates Task Vectors [[pdf]](https://arxiv.org/pdf/2310.15916) [[code]](https://github.com/roeehendel/icl_task_vectors)
- Style Vectors for Steering Generative Large Language Models [[pdf]](https://aclanthology.org/2024.findings-eacl.52.pdf) [[code]](https://github.com/DLR-SC/style-vectors-for-steering-llms)
- Finding Visual Task Vectors [[pdf]](https://arxiv.org/pdf/2404.05729) [[code]](https://github.com/alhojel/visual_task_vectors)
- Improving Reasoning Performance in Large Language Models via Representation Engineering [[pdf]](https://openreview.net/pdf?id=IssPhpUsKt) [[code]](https://github.com/bertramhojer/improve-reasoning-iclr-2025)
- Improving Instruction-Following in Language Models through Activation Steering [[pdf]](https://openreview.net/pdf?id=wozhdnRCtw) [[code]](https://github.com/microsoft/llm-steer-instruct)
- Do LLMs ``know'' internally when they follow instructions? [[pdf]](https://openreview.net/pdf?id=qIN5VDdEOr) [[code]](https://github.com/apple/ml-internal-llms-instruction-following)
- Analyzing Fine-tuning Representation Shift for Multimodal LLMs Steering [[pdf]](https://arxiv.org/pdf/2501.03012) [[code]](https://github.com/mshukor/xl-vlms) [[website]](https://pegah-kh.github.io/projects/lmm-finetuning-analysis-and-steering/)

## Hallucinations in VLMs
- Object Hallucination in Image Captioning [[pdf]](https://arxiv.org/pdf/1809.02156) [[code]](https://github.com/LisaAnne/Hallucination)
- Revealing and Reducing Gender Biases in Vision and Language Assistants (VLAs) [[pdf]](https://openreview.net/pdf?id=oStNAMWELS) [[code]](https://github.com/ExplainableML/vla-gender-bias)
- Understanding and Mitigating Hallucination in Large Vision-Language Models via Modular Attribution and Intervention [[pdf]](https://openreview.net/pdf?id=Bjq4W7P2Us) [[code]](https://github.com/TianyunYoung/Hallucination-Attribution)
- Visual Evidence Prompting Mitigates Hallucinations in Large Vision-Language Models [[pdf]](https://aclanthology.org/2025.acl-long.205.pdf)
- **[VOLCANO]** Mitigating Multimodal Hallucination through Self-Feedback Guided Revision [[pdf]](https://aclanthology.org/2024.naacl-long.23.pdf) [[code]](https://github.com/kaistAI/Volcano)
- **[VTI]** Reducing Hallucinations in Large Vision-Language Models via Latent Space Steering [[pdf]](https://openreview.net/pdf?id=LBl7Hez0fF) [[code]](https://github.com/shengliu66/VTI)
- **[HALC]** Object Hallucination Reduction via Adaptive Focal-Contrast Decoding [[pdf]](https://openreview.net/pdf/9f7eee6b5f8549258da4053b54868dd8749dc357.pdf) [[code]](https://github.com/BillChan226/HALC)
- **[VCD]** Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding [[pdf]](https://arxiv.org/pdf/2311.16922) [[code]](https://github.com/DAMO-NLP-SG/VCD)
- **[PAI]** Paying More Attention to Image: A Training-Free Method for Alleviating Hallucination in LVLMs [[pdf]](https://arxiv.org/pdf/2407.21771) [[code]](https://github.com/LALBJ/PAI) [[website]](https://lalbj.github.io/projects/PAI/)
- **[ProjectAway]** Interpreting and Editing Vision-Language Representations to Mitigate Hallucinations [[pdf]](https://openreview.net/pdf?id=94kQgWXojH) [[code]](https://github.com/nickjiang2378/vl-interp/) [[webpage]](https://anishk23733.github.io/vl-interp/)
- **[PerturboLLaVA]** Reducing Multimodal Hallucinations with Perturbative Visual Training [[pdf]](https://openreview.net/pdf?id=j4LITBSUjs) [[code]](https://github.com/aim-uofa/PerturboLLaVA)
- **[AGLA]** Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention [[pdf]](https://arxiv.org/pdf/2406.12718) [[code]](https://github.com/Lackel/AGLA)
- **[SID]** Self-Introspective Decoding: Alleviating Hallucinations for Large Vision-Language Models [[pdf]](https://openreview.net/pdf?id=rsZwwjYHuD)
- **[DeCo]** Dynamic Correction Decoding for Hallucination Mitigation [[pdf]](https://openreview.net/pdf?id=4z3IguA4Zg) [[code]](https://github.com/zjunlp/DeCo)
- **[OPERA]** Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation [[pdf]](https://arxiv.org/pdf/2311.17911) [[code]](https://github.com/shikiw/OPERA)
- **[ED]** Mitigating Multimodal Hallucination via Attention-Guided Ensemble Decoding [[pdf]](https://openreview.net/pdf?id=ziw5bzg2NO)
- **[VDGD]** Visual Description Grounding Reduces Hallucinations and Boosts Reasoning in LVLMs [[pdf]](https://openreview.net/pdf?id=3PRvlT8b1R)
- **[LURE]** Analyzing and Mitigating Object Hallucination in Large Vision-Language Models [[pdf]](https://openreview.net/pdf?id=oZDJKTlOUe) [[code]](https://github.com/YiyangZhou/LURE)
- **[HIO]** Alleviating Hallucinations in Large Vision-Language Models through Hallucination-Induced Optimization [[pdf]](https://openreview.net/pdf?id=SF2GlFhVsS) [[code]](https://github.com/BT-C/HIO)
- **[MARINE]** Mitigating Object Hallucination in Large Vision-Language Models via Image-Grounded Guidance [[pdf]](https://openreview.net/pdf?id=w0xYx9CJhY) [[code]](https://github.com/Linxi-ZHAO/MARINE)
- **[SECOND]** Mitigating Perceptual Hallucination in Vision-Language Models via Selective and Contrastive Decoding [[pdf]](https://openreview.net/attachment?id=SbyrpBNNs4&name=pdf) [[code]](https://github.com/AIDASLab/SECOND)
- **[GLSim]** Detecting Object Hallucinations in LVLMs via Global-Local Similarity [[pdf]](https://arxiv.org/pdf/2508.19972) [[code]](https://github.com/deeplearning-wisc/glsim)
- **[Dropout Decoding]** From Uncertainty to Trust: Enhancing Reliability in Vision-Language Models with Uncertainty-Guided Dropout Decoding [[pdf]](https://arxiv.org/pdf/2412.06474) [[code]](https://github.com/kigb/DropoutDecoding) 

## Interpreting and Analyzing VLMs
- Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers [[pdf]](https://arxiv.org/pdf/2103.15679.pdf) [[code]](https://github.com/hila-chefer/Transformer-MM-Explainability) 
- Can we talk models into seeing the world differently? [[pdf]](https://openreview.net/pdf?id=iVMcYxTiVM) [[code]](https://github.com/paulgavrikov/vlm_shapebias)
- Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs [[pdf]](https://arxiv.org/pdf/2401.06209)
- Why are Visually-Grounded Language Models Bad at Image Classification? [[pdf]](https://arxiv.org/pdf/2405.18415) [[code]](https://github.com/yuhui-zh15/VLMClassifier) [[website]](https://yuhui-zh15.github.io/VLMClassifier-Website/)
- Multimodal Neurons in Artificial Neural Networks [[pdf]](https://distill.pub/2021/multimodal-neurons/)
- Multimodal Neurons in Pretrained Text-Only Transformers [[pdf]](https://arxiv.org/pdf/2308.01544.pdf) [[website]](https://multimodal-interpretability.csail.mit.edu/Multimodal-Neurons-in-Text-Only-Transformers/)
- Towards Interpreting Visual Information Processing in Vision-Language Models [[pdf]](https://openreview.net/pdf?id=chanJGoa7f) [[code]](https://github.com/clemneo/llava-interp) [[demo]](https://clementneo.com/llava_logit_lens/) 
- Mechanistic Interpretability Meets Vision Language Models: Insights and Limitations [[blog]](https://d2jud02ci9yv69.cloudfront.net/2025-04-28-vlm-understanding-29/blog/vlm-understanding/)
- A Survey on Mechanistic Interpretability for Multi-Modal Foundation Models [[pdf]](https://arxiv.org/pdf/2502.17516)
- Should VLMs be Pre-trained with Image Data? [[pdf]](https://openreview.net/pdf?id=Pj4Aid3XqL)
- Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters [[pdf]](https://openreview.net/pdf?id=6VhDQP7WGX)
- Visual Classification via Description from Large Language Models [[pdf]](https://arxiv.org/pdf/2210.07183.pdf) [[code]](https://github.com/sachit-menon/classify_by_description_release) [[website]](https://cv.cs.columbia.edu/sachit/classviadescr/)
- Disentangling visual and written concepts in CLIP [[pdf]](https://arxiv.org/pdf/2206.07835.pdf) [[code]](https://github.com/joaanna/disentangling_spelling_in_clip) [[website]](https://joaanna.github.io/disentangling_spelling_in_clip/)
- MLLMs Know Where to Look: Training-free Perception of Small Visual Details with Multimodal LLMs [[pdf]](https://openreview.net/pdf?id=DgaY5mDdmT) [[code]](https://github.com/saccharomycetes/mllms_know)
- Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations? [[pdf]](https://openreview.net/pdf?id=lCasyP21Bf) [[code]](https://github.com/Heidelberg-NLP/CC-SHAP-VLM)
- Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels? [[pdf]](https://arxiv.org/pdf/2307.11978) [[code]](https://github.com/CEWu/PTNL)
- Why Is Spatial Reasoning Hard for VLMs? An Attention Mechanism Perspective on Focus Areas [[pdf]](https://arxiv.org/pdf/2503.01773) [[code]](https://github.com/shiqichen17/AdaptVis)
- Mechanistic Interpretability for AI Safety — A Review [[blog]](https://leonardbereska.github.io/blog/2024/mechinterpreview/)
- Understanding Information Storage and Transfer in Multi-modal Large Language Models [[pdf]](https://openreview.net/pdf?id=s63dtq0mwA)
- Are Vision-Language Transformers Learning Multimodal Representations? A Probing Perspective [[pdf]](https://cdn.aaai.org/ojs/21375/21375-13-25388-1-2-20220628.pdf) [[code]](https://github.com/ejsalin/vlm-probing)
- Probing Image–Language Transformers for Verb Understanding [[pdf]](https://arxiv.org/pdf/2106.09141)
- Vision Language Models are Biased [[pdf]](https://arxiv.org/pdf/2505.23941) [[code]](https://github.com/anvo25/vlms-are-biased) [[website]](https://vlmsarebiased.github.io/)
- Unveiling Visual Perception in Language Models: An Attention Head Analysis Approach [[pdf]](https://arxiv.org/pdf/2412.18108)
- **[LocalizationHeads]** Your Large Vision-Language Model Only Needs A Few Attention Heads For Visual Grounding [[pdf]](https://arxiv.org/pdf/2503.06287) [[code]](https://github.com/seilk/LocalizationHeads)
- **[TokenRank]** Attention (as Discrete-Time Markov) Chains [[pdf]](https://arxiv.org/pdf/2507.17657) [[code]](https://github.com/yoterel/attention_chains_code) [[website]](https://yoterel.github.io/attention_chains/)
- **[LLaVA-CAM]** From Redundancy to Relevance: Information Flow in LVLMs Across Reasoning Tasks [[pdf]](https://aclanthology.org/2025.naacl-long.115.pdf) [[code]](https://github.com/zhangbaijin/From-Redundancy-to-Relevance)
- **[LFA]** Black Box Few-Shot Adaptation for Vision-Language models [[pdf]](https://arxiv.org/pdf/2304.01752) [[code]](https://github.com/saic-fi/LFA)
- **[IPLoc]** Teaching VLMs to Localize Specific Objects from In-context Examples [[pdf]](https://arxiv.org/pdf/2411.13317) [[code]](https://github.com/SivanDoveh/IPLoc)
- **[PIN]** Positional Insert Unlocks Object Localisation Abilities in VLMs [[pdf]](https://arxiv.org/pdf/2402.08657) [[code]](https://github.com/QUVA-Lab/PIN/) [[website]](https://quva-lab.github.io/PIN/)
- **[GEM]** Emerging Localization Properties in Vision-Language Transformers [[pdf]](https://arxiv.org/pdf/2312.00878) [[code]](https://github.com/WalBouss/GEM)
- **[VAR]** See What You Are Told: Visual Attention Sink in Large Multimodal Models [[pdf]](https://openreview.net/pdf?id=7uDI7w5RQA) 
- **[LiMBeR]** Linearly Mapping from Image to Text Space [[pdf]](https://openreview.net/pdf?id=8tYRqb05pVn) [[code]](https://github.com/jmerullo/limber)
- **[Cambrian-1]** A Fully Open, Vision-Centric Exploration of Multimodal LLMs [[pdf]](https://openreview.net/pdf?id=Vi8AepAXGy) [[code]](https://github.com/cambrian-mllm/cambrian) [[website]](https://cambrian-mllm.github.io/) [[models]](https://huggingface.co/collections/nyu-visionx/cambrian-1-models-666fa7116d5420e514b0f23c)
- **[CoX-LMM]** A Concept-Based Explainability Framework for Large Multimodal Models [[pdf]](https://openreview.net/pdf?id=MvjLRFntW6) [[code]](https://github.com/mshukor/xl-vlms)
- **[CLIP as RNN]** Segment Countless Visual Concepts without Training Endeavor [[pdf]](https://arxiv.org/pdf/2312.07661) [[code]](https://github.com/google-research/google-research/tree/master/clip_as_rnn) [[website]](https://torrvision.com/clip_as_rnn/)
- **[CLIP-ES]** A Text-Driven Approach for Weakly Supervised Semantic Segmentation [[pdf]](https://arxiv.org/pdf/2212.09506) [[code]](https://github.com/linyq2117/CLIP-ES)
- **[SpLiCE]** Interpreting CLIP with Sparse Linear Concept Embeddings [[pdf]](https://openreview.net/pdf?id=7UyBKTFrtd) [[code]](https://github.com/AI4LIFE-GROUP/SpLiCE)
- **[VDR]** Retrieval-based Disentangled Representation Learning with Natural Language Supervision [[pdf]](https://openreview.net/pdf?id=ZlQRiFmq7Y) [[code]](https://github.com/jzhoubu/VDR)
- **[MMNeuron]** Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model [[pdf]](https://arxiv.org/pdf/2406.11193) [[code]](https://github.com/Z1zs/MMNeuron)
- **[MM1.5]** Methods, Analysis & Insights from Multimodal LLM Fine-tuning [[pdf]](https://openreview.net/pdf?id=HVtu26XDAA)
- **[VALUE]** Revealing the Secrets of Pre-trained Vision-and-Language Models [[pdf]](https://arxiv.org/pdf/2005.07310) [[code]](https://github.com/JizeCao/VALUE)
- **[GLOV]** Guided Large Language Models as Implicit Optimizers for Vision Language Models [[pdf]](https://arxiv.org/pdf/2410.06154) [[code]](https://github.com/jmiemirza/GLOV)
- **[AttackVLM]** On Evaluating Adversarial Robustness of Large Vision-Language Models [[pdf]](https://openreview.net/pdf?id=xbbknN9QFs) [[code]](https://github.com/yunqing-me/AttackVLM) [[website]](https://yunqing-me.github.io/AttackVLM/)
- **[W_CLIP]** Whitened CLIP as a Likelihood Surrogate of Images and Captions [[pdf]](https://arxiv.org/pdf/2505.06934) [[code]](https://github.com/rbetser/W_CLIP/tree/main)
- **[MirrorCLIP]** Disentangling text from visual images through reflection [[pdf]](https://openreview.net/pdf?id=FYm8coxdiR) [[code]](https://github.com/tcwangbuaa/MirrorCLIP)
- **[MMPerspective]** Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness [[pdf]](https://arxiv.org/pdf/2505.20426) [[code]](https://github.com/yunlong10/MMPerspective) [[website]](https://yunlong10.github.io/MMPerspective/)
- **[DriveBench]** Are VLMs Ready for Autonomous Driving? An Empirical Study from the Reliability, Data, and Metric Perspectives [[pdf]](https://arxiv.org/pdf/2501.04003) [[code]](https://github.com/worldbench/drivebench) [[website]](https://drive-bench.github.io/)
- **[AdaptVis]** Why Is Spatial Reasoning Hard for VLMs? An Attention Mechanism Perspective on Focus Areas [[pdf]](https://arxiv.org/pdf/2503.01773) [[code]](https://github.com/shiqichen17/AdaptVis)
 
## VLMs with Thinking/Reasoning
- **[Multimodal-CoT]** Multimodal Chain-of-Thought Reasoning in Language Models [[pdf]](https://arxiv.org/pdf/2302.00923.pdf) [[code]](https://github.com/amazon-science/mm-cot)
- **[CCoT]** Compositional Chain-of-Thought Prompting for Large Multimodal Models [[pdf]](https://arxiv.org/pdf/2311.17076.pdf) [[code]](https://github.com/chancharikmitra/CCoT)
- **[DDCoT]** Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models [[pdf]](https://openreview.net/pdf?id=ktYjrgOENR) [[code]](https://github.com/SooLab/DDCOT) [[website]](https://toneyaya.github.io/ddcot/)
- **[DCoT]** Dual Chain-of-Thought Prompting for Large Multimodal Models [[pdf]](https://openreview.net/pdf?id=0saecDOdh2) 
- **[TextCoT]** Zoom In for Enhanced Multimodal Text-Rich Image Understanding [[pdf]](https://arxiv.org/pdf/2404.09797) [[code]](https://github.com/bzluan/TextCoT)
- **[Visual CoT]** Advancing Multi-Modal Language Models with a Comprehensive Dataset and Benchmark for Chain-of-Thought Reasoning [[pdf]](https://arxiv.org/pdf/2403.16999) [[code]](https://github.com/deepcs233/Visual-CoT) [[website]](https://hao-shao.com/projects/viscot.html) [[dataset]](https://huggingface.co/datasets/deepcs233/Visual-CoT)
- **[LLaVA-CoT]** Let Vision Language Models Reason Step-by-Step [[pdf]](https://arxiv.org/pdf/2411.10440) [[code]](https://github.com/PKU-YuanGroup/LLaVA-CoT) [[dataset]](https://huggingface.co/collections/Xkev/llava-cot)
- **[LLaVA-Reasoner-DPO]** Improve Vision Language Model Chain-of-thought Reasoning [[pdf]](https://arxiv.org/pdf/2410.16198) [[code]](https://github.com/RifleZhang/LLaVA-Reasoner-DPO)
- **[VoCoT]** Unleashing Visually Grounded Multi-Step Reasoning in Large Multi-Modal Models [[pdf]](https://arxiv.org/pdf/2405.16919) [[code]](https://github.com/RupertLuo/VoCoT) 
- **[HoneyBee]** Data Recipes for Vision-Language Reasoners [[pdf]](https://arxiv.org/pdf/2510.12225) [[dataset]](https://huggingface.co/datasets/facebook/HoneyBee)
- **[CoS]** Interactive Reasoning Improves Large Vision-Language Models [[pdf]](https://arxiv.org/pdf/2403.12966) [[code]](https://github.com/dongyh20/Chain-of-Spot) [[website]](https://sites.google.com/view/chain-of-spot)
- **[DetToolChain]** A New Prompting Paradigm to Unleash Detection Ability of MLLM [[pdf]](https://arxiv.org/pdf/2403.12488) [[code]](https://github.com/yixuan730/DetToolChain)
- **[Whiteboard-of-Thought]**  Thinking Step-by-Step Across Modalities [[pdf]](https://arxiv.org/pdf/2406.14562) [[code]](https://github.com/cvlab-columbia/wot) [[website]](https://whiteboard.cs.columbia.edu/)
- **[STIC]** Enhancing Large Vision Language Models with Self-Training on Image Comprehension [[pdf]](https://arxiv.org/pdf/2405.19716) [[code]](https://github.com/yihedeng9/STIC) [[website]](https://stic-lvlm.github.io/)
- **[UniBench]** Visual Reasoning Requires Rethinking Vision-Language Beyond Scaling [[pdf]](https://openreview.net/pdf?id=g1Zn0XPUFF) [[code]](https://github.com/facebookresearch/unibench)
- **[Pixel Reasoner]** Incentivizing Pixel-Space Reasoning with Curiosity-Driven Reinforcement Learning [[pdf]](https://arxiv.org/pdf/2505.15966) [[code]](https://github.com/TIGER-AI-Lab/Pixel-Reasoner) [[website]](https://tiger-ai-lab.github.io/Pixel-Reasoner/)
- **[GRIT]** Teaching MLLMs to Think with Images [[pdf]](https://arxiv.org/pdf/2505.15879) [[code]](https://github.com/eric-ai-lab/GRIT) [[website]](https://grounded-reasoning.github.io/)
- **[RH-AUC]** More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models [[pdf]](https://arxiv.org/pdf/2505.21523) [[code]](https://github.com/MLRM-Halu/MLRM-Halu) [[website]](https://mlrm-halu.github.io/)
- **[LVR]** Latent Visual Reasoning [[pdf]](https://arxiv.org/pdf/2509.24251) [[code]](https://github.com/VincentLeebang/lvr) [[website]](https://vincentleebang.github.io/lvr-project-page/)
- **[GLM-4.5V, GLM-4.1V-Thinking]** Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning [[pdf]](https://arxiv.org/pdf/2507.01006) [[code]](https://github.com/zai-org/GLM-V)
- **[R1-Onevision]** Advancing Generalized Multimodal Reasoning through Cross-Modal Formalization [[pdf]](https://arxiv.org/pdf/2503.10615) [[code]](https://github.com/Fancy-MLLM/R1-Onevision)
- **[LlamaV-o1]** Rethinking Step-by-step Visual Reasoning in LLMs [[pdf]](https://arxiv.org/pdf/2501.06186) [[code]](https://github.com/mbzuai-oryx/LlamaV-o1) [[website]](https://mbzuai-oryx.github.io/LlamaV-o1/)
- **[Virgo]** A Preliminary Exploration on Reproducing o1-like MLLM [[pdf]](https://arxiv.org/pdf/2501.01904) [[code]](https://github.com/RUCAIBox/Virgo)
- **[Mulberry]** Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search [[pdf]](https://openreview.net/pdf/9f7906d97cbad7d32b01e7d4c0d3b45eaebfba7c.pdf) [[code]](https://github.com/HJYao00/Mulberry) 
- **[Insight-V]** Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models [[pdf]](https://arxiv.org/pdf/2411.14432) [[code]](https://github.com/dongyh20/Insight-V)
- **[VL-Rethinker]** Incentivizing Self-Reflection of Vision-Language Models with Reinforcement Learning [[pdf]](https://openreview.net/pdf?id=4oYxzssbVg) [[code]](https://github.com/TIGER-AI-Lab/VL-Rethinker) [[website]](https://tiger-ai-lab.github.io/VL-Rethinker/) [[dataset]](https://huggingface.co/datasets/TIGER-Lab/ViRL39K)
- **[Perception-R1]** Pioneering Perception Policy with Reinforcement Learning [[pdf]](https://openreview.net/pdf/295cac79046d44e50b6d8b20590b41e011777405.pdf) [[code]](https://github.com/linkangheng/PR1)
- **[MedVLM-R1]** Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning [[pdf]](https://arxiv.org/pdf/2502.19634) [[code]](https://huggingface.co/JZPeterPan/MedVLM-R1)
- **[MM-Eureka]** Exploring the Frontiers of Multimodal Reasoning with Rule-based Reinforcement Learning [[pdf]](https://arxiv.org/pdf/2503.07365) [[code]](https://github.com/ModalMinds/MM-EUREKA) [[dataset]](https://huggingface.co/datasets/FanqingM/MMK12)
- **[TTRV]** Test-Time Reinforcement Learning for Vision Language Models [[pdf]](https://arxiv.org/pdf/2510.06783) [[code]](https://github.com/Akshit21112002/TTRV) [[website]](https://akshit21112002.github.io/ttrvproject/)
- Empowering Lightweight MLLMs with Reasoning via Long CoT SFT [[pdf]](https://arxiv.org/pdf/2509.03321v1) [[code]](https://github.com/LinYuOu/mm-math-reason)
- SFT or RL? An Early Investigation into Training R1-Like Reasoning Large Vision-Language Models [[pdf]](https://openreview.net/pdf?id=wZI5qkQeDF) [[code]](https://github.com/UCSC-VLAA/VLAA-Thinking) [[website]](https://ucsc-vlaa.github.io/VLAA-Thinking/)
- Multimodal Chain-of-Thought Reasoning: A Comprehensive Survey [[pdf]](https://arxiv.org/pdf/2503.12605) [[code]](https://github.com/yaotingwangofficial/Awesome-MCoT)

## VLMs with Negations
- How and where does CLIP process negation? [[pdf]](https://arxiv.org/pdf/2407.10488)
- **[NegBench]** Vision-Language Models Do Not Understand Negation [[pdf]](https://arxiv.org/pdf/2501.09425) [[code]](https://github.com/m1k2zoo/negbench) [[website]](https://negbench.github.io/)
- **[NegCLIP]** When and why vision-language models behave like bags-of-words, and what to do about it? [[pdf]](https://openreview.net/pdf?id=KRLUvxh8uaX) [[code]](https://github.com/mertyg/vision-language-models-are-bows)
- **[ConCLIP]** Learning the Power of “No”: Foundation Models with Negations [[pdf]](https://openaccess.thecvf.com/content/WACV2025/papers/Singh_Learning_the_Power_of_No_Foundation_Models_with_Negations_WACV_2025_paper.pdf) [[supp]](https://openaccess.thecvf.com/content/WACV2025/supplemental/Singh_Learning_the_Power_WACV_2025_supplemental.pdf) [[code]](https://github.com/jaisidhsingh/CoN-CLIP)
- **[NegVQA]** Can Vision Language Models Understand Negation? [[pdf]](https://arxiv.org/pdf/2505.22946) [[code]](https://github.com/yuhui-zh15/NegVQA) [[website]](https://yuhui-zh15.github.io/NegVQA/)
- **[VALSE]** A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena [[pdf]](https://arxiv.org/pdf/2112.07566) [[code]](https://github.com/Heidelberg-NLP/VALSE)
- **[CREPE]** Can Vision-Language Foundation Models Reason Compositionally? [[pdf]](https://arxiv.org/pdf/2212.07796) [[code]](https://github.com/RAIVNLab/CREPE)
- **[SugarCrepe]** Fixing Hackable Benchmarks for Vision-Language Compositionality [[pdf]](https://arxiv.org/pdf/2306.14610) [[code]](https://github.com/RAIVNLab/sugar-crepe)
- **[NegationCLIP]** Know “No” Better: A Data-Driven Approach for Enhancing Negation Awareness in CLIP [[pdf]](https://arxiv.org/pdf/2501.10913) [[code]](https://github.com/parkquasar/NegationCLIP)
- **[NeIn]** Telling What You Don’t Want [[pdf]](https://openaccess.thecvf.com/content/CVPR2025W/SyntaGen/papers/Bui_NeIn_Telling_What_You_Dont_Want_CVPRW_2025_paper.pdf) [[code]](https://github.com/tanbuinhat/NeIn) [[website]](https://tanbuinhat.github.io/NeIn/)
- **[DCSM]** Is CLIP ideal? No. Can we fix it? Yes! [[pdf]](https://arxiv.org/pdf/2503.08723) [[code]](https://github.com/Raphoo/DCSM_Ideal_CLIP)

## Modality Gap in VLMs
-  Understanding the Modality Gap in Multi-modal Contrastive Representation Learning [[pdf]](https://arxiv.org/pdf/2203.02053) [[code]](https://github.com/Weixin-Liang/Modality-Gap)
-  Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Models [[pdf]](https://openreview.net/pdf?id=uAFHCZRmXk) [[code]](https://github.com/lmb-freiburg/two-effects-one-trigger)
-  Implicit Multimodal Alignment: On the Generalization of Frozen LLMs to Multimodal Inputs [[pdf]](https://openreview.net/pdf?id=9622QfVSAb) [[code]](https://github.com/mshukor/ima-lmms)

## Generative Models
- **[GAN Dissection]**: Visualizing and Understanding Generative Adversarial Networks [[pdf]](https://openreview.net/pdf?id=Hyg_X2C5FX) [[code]](https://github.com/CSAILVision/GANDissect) [[website]](http://gandissect.csail.mit.edu/)
- **[GANSpace]** Discovering Interpretable GAN Controls [[pdf]](https://proceedings.neurips.cc/paper/2020/file/6fe43269967adbb64ec6149852b5cc3e-Paper.pdf) [[code]](https://github.com/harskish/ganspace)
- **[CBGM]** Concept Bottleneck Generative Models [[pdf]](https://openreview.net/pdf?id=L9U5MJJleF) [[code]](https://github.com/prescient-design/CBGM)
- **[Conceptor]** The Hidden Language of Diffusion Models [[pdf]](https://openreview.net/pdf?id=awWpHnEJDw) [[code]](https://github.com/hila-chefer/Conceptor) [[website]](https://hila-chefer.github.io/Conceptor/)
- **[DAAM]** Interpreting Stable Diffusion Using Cross Attention [[pdf]](https://arxiv.org/pdf/2210.04885.pdf) [[code]](https://github.com/castorini/daam) [[demo]](https://huggingface.co/spaces/tetrisd/Diffusion-Attentive-Attribution-Maps)
- **[CB-AE]** Interpretable Generative Models through Post-hoc Concept Bottlenecks [[pdf]](https://arxiv.org/pdf/2503.19377) [[code]](https://github.com/Trustworthy-ML-Lab/posthoc-generative-cbm) [[website]](https://lilywenglab.github.io/posthoc-generative-cbm/)
- **[Cones]** Concept Neurons in Diffusion Models for Customized Generation [[pdf]](https://proceedings.mlr.press/v202/liu23j/liu23j.pdf)
- **[VisCoIN]** Restyling Unsupervised Concept Based Interpretable Networks with Generative Models [[pdf]](https://openreview.net/pdf?id=CexatBp6rx) [[code]](https://github.com/GnRlLeclerc/VisCoIN) [[website]](https://jayneelparekh.github.io/VisCoIN_project_page/)
- **[Diffusion Explainer]** Visual Explanation for Text-to-image Stable Diffusion [[pdf]](https://arxiv.org/pdf/2305.03509.pdf) [[website]](https://poloclub.github.io/diffusion-explainer/) [[video]](https://www.youtube.com/watch?v=Zg4gxdIWDds&ab_channel=PoloClubofDataScience)
- **[DiffEx]** Explaining a Classifier Through Hierarchical Semantics with Text-to-Image Diffusion Models [[pdf]](https://arxiv.org/pdf/2412.18604) [[website]](https://explain-in-diffusion.github.io/)
- **[ConceptExpress]** Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction [[pdf]](https://arxiv.org/pdf/2407.07077) [[code]](https://github.com/haoosz/ConceptExpress)
- **[ConceptAttention]** Diffusion Transformers Learn Highly Interpretable Features [[pdf]](https://arxiv.org/pdf/2502.04320) [[code]](https://github.com/helblazer811/ConceptAttention) [[website]](https://alechelbling.com/ConceptAttention/) [[demo]](https://huggingface.co/spaces/helblazer811/ConceptAttention)
- **[CONFORM]** Contrast is All You Need For High-Fidelity Text-to-Image Diffusion Models [[pdf]](https://arxiv.org/pdf/2312.06059) [[code]](https://github.com/gemlab-vt/CONFORM) [[website]](https://conform-diffusion.github.io/)
- **[Self-Guidance]** Diffusion Self-Guidance for Controllable Image Generation [[pdf]](https://openreview.net/pdf?id=qgv56R2YJ7) [[code]](https://colab.research.google.com/drive/1SEM1R9mI9cF-aFpqg3NqHP8gN8irHuJi?usp=sharing) [[website]](https://dave.ml/selfguidance/)
- **[DIFT]** Emergent Correspondence from Image Diffusion [[pdf]](https://openreview.net/pdf?id=ypOiXjdfnU) [[code]](https://github.com/Tsingularity/dift) [[website]](https://diffusionfeatures.github.io/) [[colab]](https://colab.research.google.com/drive/1km6MGafhAvbPOouD3oo64aUXgLlWM6L1?usp=sharing)
- **[Asyrp]** Diffusion Models Already Have A Semantic Latent Space [[pdf]](https://openreview.net/pdf?id=pd1P2eUBVfq) [[code]](https://github.com/kwonminki/Asyrp_official) [[website]](https://kwonminki.github.io/Asyrp/)
- **[I2AM]** Interpreting Image-to-Image Latent Diffusion Models via Bi-Attribution Maps [[pdf]](https://openreview.net/pdf?id=bBNUiErs26)
- **[Attend-and-Excite]** Attention-Based Semantic Guidance for Text-to-Image Diffusion Models [[pdf]](https://arxiv.org/pdf/2301.13826) [[code]](https://github.com/yuval-alaluf/Attend-and-Excite) [[demo]](https://huggingface.co/spaces/AttendAndExcite/Attend-and-Excite) [[website]](https://yuval-alaluf.github.io/Attend-and-Excite/) [[hf]](https://huggingface.co/docs/diffusers/v0.35.1/en/api/pipelines/attend_and_excite)
- **[SEGA]** Instructing Text-to-Image Models using Semantic Guidance [[pdf]](https://openreview.net/pdf?id=KIPAIy329j) [[code]](https://github.com/ml-research/semantic-image-editing) [[code]](https://huggingface.co/docs/diffusers/api/pipelines/semantic_stable_diffusion)
- **[SAeUron]** Interpretable Concept Unlearning in Diffusion Models with Sparse Autoencoders [[pdf]](https://arxiv.org/pdf/2501.18052) [[code]](https://github.com/cywinski/SAeUron)
- **[RECE]** Reliable and Efficient Concept Erasure of Text-to-Image Diffusion Models [[pdf]](https://arxiv.org/pdf/2407.12383) [[code]](https://github.com/CharlesGong12/RECE)
- **[UCE]** Unified Concept Editing in Diffusion Models [[pdf]](https://arxiv.org/pdf/2308.14761) [[code]](https://github.com/rohitgandikota/unified-concept-editing) [[website]](https://unified.baulab.info/)
- **[Add-it]** Training-Free Object Insertion in Images With Pretrained Diffusion Models [[pdf]](https://openreview.net/pdf?id=ZeaTvXw080)
- **[P2P]** Prompt-to-Prompt Image Editing with Cross Attention Control [[pdf]](https://openreview.net/pdf/a6e78444f28f4790c2b8eb24364ced3ce736feb0.pdf) [[code]](https://github.com/google/prompt-to-prompt/) [[website]](https://prompt-to-prompt.github.io/)
- **[InstructPix2Pix]** Learning to Follow Image Editing Instructions [[pdf]](https://arxiv.org/pdf/2211.09800) [[code]](https://github.com/timothybrooks/instruct-pix2pix) [[website]](https://www.timothybrooks.com/instruct-pix2pix/) [[hf]](https://huggingface.co/docs/diffusers/v0.35.1/en/api/pipelines/pix2pix)
- **[weights2weights]** Interpreting the Weight Space of Customized Diffusion Models [[pdf]](https://arxiv.org/pdf/2406.09413) [[code]](https://github.com/snap-research/weights2weights) [[website]](https://snap-research.github.io/weights2weights/) [[demo]](https://huggingface.co/spaces/snap-research/weights2weights) [[video]](https://www.youtube.com/watch?v=95raWv_k08c)
- **[OPT2I]** Improving Text-to-Image Consistency via Automatic Prompt Optimization [[pdf]](https://arxiv.org/pdf/2403.17804) 
- **[DSG]** Davidsonian Scene Graph: Improving Reliability in Fine-Grained Evaluation for Text-to-Image Generation [[pdf]](https://openreview.net/pdf?id=ITq4ZRUT4a) [[code]](https://github.com/j-min/DSG) [[website]](https://google.github.io/dsg/)
- **[ADM-ES]** Elucidating the Exposure Bias in Diffusion Models [[pdf]](https://openreview.net/pdf?id=xEJMoj1SpX) [[code]](https://github.com/forever208/ADM-ES)
- **[Revelio]** Interpreting and leveraging semantic information in diffusion models [[pdf]](https://arxiv.org/pdf/2411.16725) [[code]](https://github.com/revelio-diffusion/revelio) 
- **[Stable Flow]** Vital Layers for Training-Free Image Editing [[pdf]](https://arxiv.org/pdf/2411.14430) [[code]](https://github.com/snap-research/stable-flow) [[website]](https://omriavrahami.com/stable-flow/)
- **[CASteer]** Steering Diffusion Models for Controllable Generation [[pdf]](https://arxiv.org/pdf/2503.09630) [[code]](https://github.com/Atmyre/CASteer)
- **[NAG]** Normalized Attention Guidance: Universal Negative Guidance for Diffusion Models [[pdf]](https://arxiv.org/pdf/2505.21179) [[code]](https://github.com/ChenDarYen/Normalized-Attention-Guidance)
- **[HeadHunter]** Where and How to Perturb: On the Design of Perturbation Guidance in Diffusion and Flow Models [[pdf]](https://arxiv.org/pdf/2506.10978) [[code]](https://github.com/cvlab-kaist/HeadHunter) [[website]](https://cvlab-kaist.github.io/HeadHunter/)
- **[T-GATE]** Faster Diffusion Through Temporal Attention Decomposition [[pdf]](https://openreview.net/pdf?id=xXs2GKXPnH) [[code]](https://github.com/HaozheLiu-ST/T-GATE)
- **[NP-Edit]** Learning an Image Editing Model without Image Editing Pairs [[pdf]](https://arxiv.org/pdf/2510.14978) [[website]](https://nupurkmr9.github.io/npedit/)
- VLM-Guided Adaptive Negative Prompting for Creative Generation [[pdf]](https://arxiv.org/pdf/2510.10715) [[website]](https://shelley-golan.github.io/VLM-Guided-Creative-Generation/)
- Rare Text Semantics Were Always There in Your Diffusion Transformer [[pdf]](https://arxiv.org/pdf/2510.03886) 
- Dissecting and Mitigating Diffusion Bias via Mechanistic Interpretability [[pdf]](https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_Dissecting_and_Mitigating_Diffusion_Bias_via_Mechanistic_Interpretability_CVPR_2025_paper.pdf) [[code]](https://github.com/foundation-model-research/DiffLens) [[website]](https://foundation-model-research.github.io/difflens/)
- Null-text Inversion for Editing Real Images using Guided Diffusion Models [[pdf]](https://arxiv.org/pdf/2211.09794) [[code]](https://github.com/google/prompt-to-prompt/#null-text-inversion-for-editing-real-images) [[website]](https://null-text-inversion.github.io/)
- Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf) [[code]](https://github.com/UCSB-NLP-Chang/DiffusionDisentanglement)
- Understanding Hallucinations in Diffusion Models through Mode Interpolation [[pdf]](https://arxiv.org/pdf/2406.09358) [[code]](https://github.com/locuslab/diffusion-model-hallucination)
- Interpreting and Steering Features in Images [[blog]](https://www.lesswrong.com/posts/Quqekpvx8BGMMcaem/interpreting-and-steering-features-in-images)
- Interpreting, Manipulating, and Controlling CLIP With Sparse Autoencoders [[blog]](https://www.lesswrong.com/posts/iYFuZo9BMvr6GgMs5/case-study-interpreting-manipulating-and-controlling-clip)
- Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation [[pdf]](https://arxiv.org/pdf/2211.12572) [[code]](https://github.com/MichalGeyer/plug-and-play) [[website]](https://pnp-diffusion.github.io/) [[demo]](https://huggingface.co/spaces/hysts/PnP-diffusion-features) [[demo]](https://replicate.com/daanelson/plug_and_play_image_translation)
- Towards Understanding Cross and Self-Attention in Stable Diffusion for Text-Guided Image Editing [[pdf]](https://arxiv.org/pdf/2403.03431) [[code]](https://github.com/alibaba/EasyNLP/tree/master/diffusion/FreePromptEditing)
- On Mechanistic Knowledge Localization in Text-to-Image Generative Models [[pdf]](https://arxiv.org/pdf/2405.01008) [[code]](https://github.com/samyadeepbasu/LocoGen)
- Training-Free Layout Control with Cross-Attention Guidance [[pdf]](https://arxiv.org/pdf/2304.03373) [[code]](https://github.com/silent-chen/layout-guidance) [[website]](https://silent-chen.github.io/layout-guidance/)
- Concept Algebra for (Score-Based) Text-Controlled Generative Models [[pdf]](https://openreview.net/pdf?id=SGlrCuwdsB) [[code]](https://github.com/zihao12/concept-algebra-code)
- On Memorization in Diffusion Models [[pdf]](https://openreview.net/pdf?id=D3DBqvSDbj) [[code]](https://github.com/sail-sg/DiffMemorize)
- Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation [[pdf]](https://arxiv.org/pdf/2311.17216) [[code]](https://github.com/hangligit/InterpretDiffusion) [[website]](https://interpretdiffusion.github.io/)
- Your Diffusion Model is Secretly a Zero-Shot Classifier [[pdf]](https://arxiv.org/pdf/2303.16203) [[code]](https://github.com/diffusion-classifier/diffusion-classifier) [[website]](https://diffusion-classifier.github.io/)
- Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models [[pdf]](https://arxiv.org/pdf/2306.05357) [[code]](https://github.com/nanlliu/Unsupervised-Compositional-Concepts-Discovery) [[website]](https://energy-based-model.github.io/unsupervised-concept-discovery/)
- Towards Visually Explaining Variational Autoencoders [[pdf]](https://arxiv.org/pdf/1911.07389.pdf) [[code]](https://github.com/liuem607/expVAE) [[code]](https://github.com/FrankBrongers/Reproducing_expVAE) [[video]](https://www.youtube.com/watch?v=6FqVcSAfSkI&ab_channel=ComputerVisionFoundationVideos) [[video]](https://www.youtube.com/watch?v=3XOgqhf-GZM&t=1034s&ab_channel=VipulVaibhaw)
- Localizing Knowledge in Diffusion Transformers [[pdf]](https://arxiv.org/pdf/2505.18832) [[code]](https://github.com/ArmanZarei/DiT-Knowledge-Localization) [[website]](https://armanzarei.github.io/Localizing-Knowledge-in-DiTs/)
- Extracting Training Data from Diffusion Models [[pdf]](https://arxiv.org/pdf/2301.13188)
- Why Diffusion Models Don’t Memorize: The Role of Implicit Dynamical Regularization in Training [[pdf]](https://openreview.net/pdf?id=BSZqpqgqM0) [[code]](https://github.com/tbonnair/Why-Diffusion-Models-Don-t-Memorize)

## LLM Understanding
- Interpreting GPT: The Logit Lens [[blog]](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens)
- Locating and Editing Factual Associations in GPT [[pdf]](https://arxiv.org/pdf/2202.05262.pdf) [[code]](https://github.com/kmeng01/rome) [[colab]](https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/rome.ipynb) [[colab]](https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/causal_trace.ipynb) [[video]](https://www.youtube.com/watch?v=_NMQyOu2HTo&ab_channel=YannicKilcher) [[website]](https://rome.baulab.info/)
- Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers [[pdf]](https://openreview.net/pdf?id=fzbHRjAd8U) [[code]](https://github.com/microsoft/LMOps)
- Is In-Context Learning Sufficient for Instruction Following in LLMs? [[pdf]](https://openreview.net/pdf?id=STEEDDv3zI) [[code]](https://github.com/tml-epfl/icl-alignment)
- Dissecting Recall of Factual Associations in Auto-Regressive Language Models [[pdf]](https://openreview.net/pdf?id=F1G7y94K02) [[code]](https://github.com/google-research/google-research/tree/master/dissecting_factual_predictions)
- Transformer Feed-Forward Layers Are Key-Value Memories [[pdf]](https://arxiv.org/pdf/2012.14913.pdf)
- What's New in My Data? Novelty Exploration via Contrastive Generation [[pdf]](https://openreview.net/pdf?id=IZDiRbVSVN)
- Eliciting Latent Predictions from Transformers with the Tuned Lens [[pdf]](https://arxiv.org/pdf/2303.08112) [[code]](https://github.com/AlignmentResearch/tuned-lens)
- Are self-explanations from Large Language Models faithful? [[pdf]](https://arxiv.org/pdf/2401.07927)
- Chain-of-Thought Reasoning In The Wild Is Not Always Faithful [[pdf]](https://openreview.net/pdf?id=L8094Whth0)
- LLM Evaluators Recognize and Favor Their Own Generations [[pdf]](https://openreview.net/pdf?id=4NJBV6Wp0h)
- Where does In-context Learning Happen in Large Language Models? [[pdf]](https://openreview.net/pdf?id=LLuSjg59an) [[code]](https://github.com/suzyahyah/where_does_in-context-learning_happen_in_LLMs)
- Measuring the Faithfulness of Large Language Model Explanations [[pdf]](https://openreview.net/pdf?id=4ub9gpx9xw)
- Visualizing the Reasoning Process of Large Language Models [[pdf]](https://arxiv.org/pdf/2503.22165) [[code]](https://github.com/tmlr-group/landscape-of-thoughts)
- The Same but Different: Structural Similarities and Differences in Multilingual Language Modeling [[pdf]](https://openreview.net/pdf?id=NCrFA7dq8T)
- Weight Ensembling Improves Reasoning in Language Models [[pdf]](https://arxiv.org/pdf/2504.10478)
- Demystifying Long Chain-of-Thought Reasoning in LLMs [[pdf]](https://openreview.net/pdf?id=AgtQlhMQ0V)
- Idiosyncrasies in Large Language Models [[pdf]](https://arxiv.org/pdf/2502.12150) [[code]](https://github.com/locuslab/llm-idiosyncrasies) [[website]](https://eric-mingjie.github.io/llm-idiosyncrasies/index.html)
- On the Role of Attention Heads in Large Language Model Safety [[pdf]](https://openreview.net/pdf?id=h0Ak8A5yqw) [[code]](https://github.com/ydyjya/SafetyHeadAttribution)
- Repetition Improves Language Model Embeddings [[pdf]](https://openreview.net/pdf?id=Ahlrf2HGJR)
- When More is Less: Understanding Chain-of-Thought Length in LLMs [[pdf]](https://openreview.net/pdf?id=W8dxn7hBkO)
- Training Large Language Models to Reason in a Continuous Latent Space [[pdf]](https://openreview.net/pdf?id=KrWSrrYGpT)
- TTRL: Test-Time Reinforcement Learning [[pdf]](https://openreview.net/pdf?id=VuVhgEiu20) [[code]](https://github.com/PRIME-RL/TTRL)
- Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond) [[pdf]](https://openreview.net/pdf?id=saDOrrnNTz) [[code]](https://github.com/liweijiang/artificial-hivemind) [[dataset]](https://huggingface.co/collections/liweijiang/artificial-hivemind)

## Miscellaneous
- [Entropy Blog](https://alessiodevoto.github.io/blog/)
